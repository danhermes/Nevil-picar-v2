This project is mostly synthesized but needing some creative assembly and integration of SDKs: Working faithfully from "docs/Nevil_ROS2_PREEMPT-RT_Spec_and_Code_Samples.md", I'm building a multi-threaded upgrade to Nevil 1.0 using ROS2, PREEMPT-RT, picarx and Robot hat api, action_helper.py(important, as this is the only well-tested navigation api among these). The project will included and be tested by a digital twin based upon the docs/ARCHES-PiCar-X-main.zip project, with the additiona of a text interface, and a simple voice interface for simulation. Provide excellent decoupling so digital twin can be easily swapped for the Nevil robot picar when present. Modes should include: conversation, play(automatous), sleep, shut down, etc. User can command Nevil to switch modes. Nevil should have capability for simultaneous functions on different threads: movement/action, obstruction detection/management, seeing, talking, listening, thinking (GPT calls), etc. Add SLAM functionality that Nevil may learn and map his surroundings, and these are logged and saved. Nevil should learn the locations, names and functions of different rooms and know where his main user Dan, the parrot named Chicken, and the lovely lady Danielle is, and his recharging station.  In addition to image analysis by OpenAI, add a layer of offline cognition that includes a small portable model like gemma 2 or TinyLlama, and offline object recognition using the picar object recognition model. Use context7.

Work mainly from "docs/Nevil_ROS2_PREEMPT-RT_Spec_and_Code_Samples.md. Use all the docs and zips and code projects in /docs folder as well as ROS2, PREEMPT-RT, Nevil_ROS2_Architecture.md for basic threading model, the digital twin implementation in docs/ARCHES-PiCar-X-main.zip although improve or modify this as you see fit, be aware of picarx doc like docs-sunfounder-com-picar-x-en-latest.pdf but adhere to for navigation since this is tested and works - add to it as necessary but attempt to test all nav with digital twin. Use context7 as needed for additional doc on any or all of this.